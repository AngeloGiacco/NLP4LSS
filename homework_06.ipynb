{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "present-brown",
      "metadata": {
        "id": "present-brown"
      },
      "source": [
        "# HW06: Transformers and Doc Embeddings\n",
        "\n",
        "Remember that these homework work as a completion grade. **You can skip one section of this homework.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHfPzrPBJgfM",
        "outputId": "e1761cdc-1a00-4544-dd4b-29d9b907442e"
      },
      "id": "VHfPzrPBJgfM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-01 14:53:10--  https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29470338 (28M) [text/plain]\n",
            "Saving to: ‘train.csv’\n",
            "\n",
            "train.csv           100%[===================>]  28.10M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-04-01 14:53:11 (199 MB/s) - ‘train.csv’ saved [29470338/29470338]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "irish-ending",
      "metadata": {
        "id": "irish-ending",
        "outputId": "637b79cb-e7d3-464e-f599-5120fdd09bc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        label                                              title  \\\n",
              "71647       2                     BellSouth Posts Lower Earnings   \n",
              "50545       3              Who #39;s eavesdropping on your cell?   \n",
              "94867       0                        Barroso Commission approved   \n",
              "104550      3                  Sun to buy remote-management firm   \n",
              "83863       0                   Aide: Arafat Not In Coma, In ICU   \n",
              "...       ...                                                ...   \n",
              "62089       2                       Delta warns of bigger losses   \n",
              "22201       3      Ebbers' Lawyers  Seek Immunity  For Witnesses   \n",
              "62441       1          Astros Lead Cards 5-2 After Eight Innings   \n",
              "21410       0  Russia Offers \\$10 Million for Chechen Rebels ...   \n",
              "96732       3  DNA Analyst Fired For Allegedly Mishandling Da...   \n",
              "\n",
              "                                                     lead  \\\n",
              "71647   BellSouth Corp. (BLS.N: Quote, Profile, Resear...   \n",
              "50545   LONDON: If you thought that your little chit c...   \n",
              "94867   The European Parliament has approved Jose Manu...   \n",
              "104550  Sun Microsystems has signed a deal to acquire ...   \n",
              "83863   PARIS (CBS) A senior aide to Yasser Arafat sai...   \n",
              "...                                                   ...   \n",
              "62089   No. 3 airline says loss to be worse than forec...   \n",
              "22201   Lawyers for the former WorldCom Inc. chief exe...   \n",
              "62441   Houston Astros #39; Jeff Kent homers in the fi...   \n",
              "21410    MOSCOW (Reuters) - The Russia government has ...   \n",
              "96732   LOS ANGELES -- The private laboratory that con...   \n",
              "\n",
              "                                                     text  \n",
              "71647   BellSouth Posts Lower Earnings BellSouth Corp....  \n",
              "50545   Who #39;s eavesdropping on your cell? LONDON: ...  \n",
              "94867   Barroso Commission approved The European Parli...  \n",
              "104550  Sun to buy remote-management firm Sun Microsys...  \n",
              "83863   Aide: Arafat Not In Coma, In ICU PARIS (CBS) A...  \n",
              "...                                                   ...  \n",
              "62089   Delta warns of bigger losses No. 3 airline say...  \n",
              "22201   Ebbers' Lawyers  Seek Immunity  For Witnesses ...  \n",
              "62441   Astros Lead Cards 5-2 After Eight Innings Hous...  \n",
              "21410   Russia Offers \\$10 Million for Chechen Rebels ...  \n",
              "96732   DNA Analyst Fired For Allegedly Mishandling Da...  \n",
              "\n",
              "[10000 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6c13175-1e76-44ba-be29-b47ad5874eeb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>title</th>\n",
              "      <th>lead</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>71647</th>\n",
              "      <td>2</td>\n",
              "      <td>BellSouth Posts Lower Earnings</td>\n",
              "      <td>BellSouth Corp. (BLS.N: Quote, Profile, Resear...</td>\n",
              "      <td>BellSouth Posts Lower Earnings BellSouth Corp....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50545</th>\n",
              "      <td>3</td>\n",
              "      <td>Who #39;s eavesdropping on your cell?</td>\n",
              "      <td>LONDON: If you thought that your little chit c...</td>\n",
              "      <td>Who #39;s eavesdropping on your cell? LONDON: ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94867</th>\n",
              "      <td>0</td>\n",
              "      <td>Barroso Commission approved</td>\n",
              "      <td>The European Parliament has approved Jose Manu...</td>\n",
              "      <td>Barroso Commission approved The European Parli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104550</th>\n",
              "      <td>3</td>\n",
              "      <td>Sun to buy remote-management firm</td>\n",
              "      <td>Sun Microsystems has signed a deal to acquire ...</td>\n",
              "      <td>Sun to buy remote-management firm Sun Microsys...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83863</th>\n",
              "      <td>0</td>\n",
              "      <td>Aide: Arafat Not In Coma, In ICU</td>\n",
              "      <td>PARIS (CBS) A senior aide to Yasser Arafat sai...</td>\n",
              "      <td>Aide: Arafat Not In Coma, In ICU PARIS (CBS) A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62089</th>\n",
              "      <td>2</td>\n",
              "      <td>Delta warns of bigger losses</td>\n",
              "      <td>No. 3 airline says loss to be worse than forec...</td>\n",
              "      <td>Delta warns of bigger losses No. 3 airline say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22201</th>\n",
              "      <td>3</td>\n",
              "      <td>Ebbers' Lawyers  Seek Immunity  For Witnesses</td>\n",
              "      <td>Lawyers for the former WorldCom Inc. chief exe...</td>\n",
              "      <td>Ebbers' Lawyers  Seek Immunity  For Witnesses ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62441</th>\n",
              "      <td>1</td>\n",
              "      <td>Astros Lead Cards 5-2 After Eight Innings</td>\n",
              "      <td>Houston Astros #39; Jeff Kent homers in the fi...</td>\n",
              "      <td>Astros Lead Cards 5-2 After Eight Innings Hous...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21410</th>\n",
              "      <td>0</td>\n",
              "      <td>Russia Offers \\$10 Million for Chechen Rebels ...</td>\n",
              "      <td>MOSCOW (Reuters) - The Russia government has ...</td>\n",
              "      <td>Russia Offers \\$10 Million for Chechen Rebels ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96732</th>\n",
              "      <td>3</td>\n",
              "      <td>DNA Analyst Fired For Allegedly Mishandling Da...</td>\n",
              "      <td>LOS ANGELES -- The private laboratory that con...</td>\n",
              "      <td>DNA Analyst Fired For Allegedly Mishandling Da...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6c13175-1e76-44ba-be29-b47ad5874eeb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c6c13175-1e76-44ba-be29-b47ad5874eeb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c6c13175-1e76-44ba-be29-b47ad5874eeb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-374bb9f2-485f-475f-bbd4-4e42083e8e36\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-374bb9f2-485f-475f-bbd4-4e42083e8e36')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-374bb9f2-485f-475f-bbd4-4e42083e8e36 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9936,\n        \"samples\": [\n          \"Walgreen Quarterly Profit Rises (Reuters)\",\n          \"Johnson   Johnson to Acquire Guidant\",\n          \"Raptors Sign Center Loren Woods (AP)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lead\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9984,\n        \"samples\": [\n          \"Reuters - Pakistan said on Sunday the time was ripe for progress in Kashmir, cause of two wars with neighbour India, and it hoped for quick agreement on starting a bus link between the two halves of the disputed territory.\",\n          \"Eli Lilly and Co. (LLY.N: Quote, Profile, Research) on Thursday said it expects 2005 earnings to rise as higher sales of its newer drugs offset a decline in its top-selling schizophrenia drug Zyprexa.\",\n          \"Bombardier Recreational Products Inc. said Monday it had settled a three-year-old patent infringement lawsuit filed by Simmons Inc.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10000,\n        \"samples\": [\n          \"Gaza militants seize government building GAZA CITY, Gaza Strip -- Palestinian gunmen seized the governor #39;s office in a southern city on Sunday, demanding aid for families left homeless by an Israeli military operation, witnesses said.\",\n          \"Windows installer gains .Net authoring Wise Solutions has released Wise for Windows Installer 6.0, featuring .Net support and enhanced tools for creating installations for data-driven Web applications. \",\n          \"Picture of North Sea fish decline A model of the North Sea's ecosystem suggests the total fish stock has dropped from 26 million tonnes to 10 million tonnes in just over a century.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "df = pd.read_csv('train.csv')\n",
        "def decrement(x):\n",
        "  return x - 1\n",
        "df.columns = [\"label\", \"title\", \"lead\"]\n",
        "df[\"text\"] = df[\"title\"] + \" \" + df[\"lead\"]\n",
        "df[\"label\"] = df[\"label\"].apply(decrement)\n",
        "df = df.sample(n=10000) # # only use 10K datapoints\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "regulated-klein",
      "metadata": {
        "id": "regulated-klein"
      },
      "source": [
        "## Hugginface Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "reasonable-graph",
      "metadata": {
        "id": "reasonable-graph",
        "outputId": "5a61ef14-8dc4-495a-d7c8-62a797a89777",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "from transformers import DistilBertForSequenceClassification, DistilBertConfig\n",
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print (device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "confident-village",
      "metadata": {
        "id": "confident-village",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08b59c0e-88c5-40db-83cc-3cc30974af43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "##TODO build a transformer model to do sequence classification with the goal to predict the label from the text\n",
        "model_name = 'distilbert-base-uncased' # huggingface model_ID or path to folder\n",
        "import numpy as np\n",
        "unique_labels, counts = np.unique(df[\"label\"], return_counts=True)\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=len(unique_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "psychological-object",
      "metadata": {
        "id": "psychological-object",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1f4e576-8b34-41b4-b3bc-a5c96b30d34c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBertForSequenceClassification(\n",
            "  (distilbert): DistilBertModel(\n",
            "    (embeddings): Embeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer): Transformer(\n",
            "      (layer): ModuleList(\n",
            "        (0-5): 6 x TransformerBlock(\n",
            "          (attention): MultiHeadSelfAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (activation): GELUActivation()\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "##TODO print the summary of the model\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "statistical-recommendation",
      "metadata": {
        "id": "statistical-recommendation"
      },
      "outputs": [],
      "source": [
        "##TODO split the sample into a training and a test set\n",
        "##TODO prepare the dataset for torch.\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import DistilBertTokenizerFast\n",
        "\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "X = tokenizer(list(df['text']), return_tensors=\"pt\", truncation=True, padding=True)\n",
        "y = torch.tensor(list(df['label']))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam([\n",
        "    {'params': model.distilbert.parameters(), 'lr': 1e-5},\n",
        "    {'params': model.classifier.parameters(), 'lr': 1e-3}\n",
        "])"
      ],
      "metadata": {
        "id": "xSO4pomrOKki"
      },
      "id": "xSO4pomrOKki",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['text'].tolist(), df['label'].tolist(), test_size=.2)\n",
        "\n",
        "X_train, X_test, y_train, y_test = np.array(X_train[:1600]), np.array(X_test[:400]), np.array(y_train[:1600]), np.array(y_test[:400])\n",
        "print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = X_train.reshape(-1, 16), X_test.reshape(-1, 16), y_train.reshape(-1, 16), y_test.reshape(-1, 16) # create batches of 16\n",
        "print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "\n",
        "X_train, X_test = X_train.tolist(), X_test.tolist()"
      ],
      "metadata": {
        "id": "Gjjngxr2NaRu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f8c9f1-597b-47ab-c0e3-21a01d93293c"
      },
      "id": "Gjjngxr2NaRu",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1600,) (400,) (1600,) (400,)\n",
            "(100, 16) (25, 16) (100, 16) (25, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FduEWrwNMKy",
        "outputId": "eada8345-0009-4340-a42f-14e6293af972"
      },
      "id": "6FduEWrwNMKy",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 10000 entries, 71647 to 96732\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   label   10000 non-null  int64 \n",
            " 1   title   10000 non-null  object\n",
            " 2   lead    10000 non-null  object\n",
            " 3   text    10000 non-null  object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 390.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "piano-compound",
      "metadata": {
        "id": "piano-compound"
      },
      "outputs": [],
      "source": [
        "##TODO fit the model and print the obtained accuracy (hint: you can follow the training steps in the notebook. To learn more, checkout the trainer class of huggingface transformers)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 1\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "\n",
        "    for text, labels in tqdm(zip(X_train, y_train), total=len(X_train)):\n",
        "        model_inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=256)\n",
        "        labels = torch.tensor(labels).long().to(device)\n",
        "        model_inputs = {k: v.to(device) for k, v in model_inputs.items()}\n",
        "        outputs = model(**model_inputs, labels = labels)\n",
        "        loss, logits = outputs[:2]\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYmpfOWIP8dw",
        "outputId": "0e7cfaa4-ab55-4238-f371-854b99874d32"
      },
      "id": "NYmpfOWIP8dw",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [13:39<00:00,  8.19s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, targets = [], []\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for text, labels in tqdm(zip(X_test, y_test), total=len(X_test)):\n",
        "        model_inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        model_inputs = {k:v.to(device) for k,v in model_inputs.items()}\n",
        "\n",
        "        output = model(**model_inputs)\n",
        "        logits = output[0]\n",
        "        predictions.extend(logits.argmax(dim=1).tolist())\n",
        "        targets.extend(labels)\n",
        "\n",
        "from sklearn import metrics\n",
        "accuracy = metrics.accuracy_score(targets, predictions)\n",
        "print (\"accuracy\", accuracy)\n",
        "classification_report = metrics.classification_report(targets, predictions)\n",
        "print (classification_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHz8HQ_pWDbl",
        "outputId": "c5e96da5-34c9-4e29-8c44-e8a745809667"
      },
      "id": "hHz8HQ_pWDbl",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [01:01<00:00,  2.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.84\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85       104\n",
            "           1       0.96      0.88      0.92        77\n",
            "           2       0.80      0.86      0.83       124\n",
            "           3       0.82      0.75      0.78        95\n",
            "\n",
            "    accuracy                           0.84       400\n",
            "   macro avg       0.85      0.84      0.84       400\n",
            "weighted avg       0.84      0.84      0.84       400\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7fe3a17",
      "metadata": {
        "id": "e7fe3a17"
      },
      "source": [
        "# Doc Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "3b41f71c",
      "metadata": {
        "id": "3b41f71c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aca463fb-5a03-4999-82a6-d5a6a0d8ebb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-01 15:57:36--  http://alt.qcri.org/semeval2017/task1/data/uploads/sts2017.eval.v1.1.zip\n",
            "Resolving alt.qcri.org (alt.qcri.org)... 37.186.61.205\n",
            "Connecting to alt.qcri.org (alt.qcri.org)|37.186.61.205|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://alt.qcri.org/semeval2017/task1/data/uploads/sts2017.eval.v1.1.zip [following]\n",
            "--2024-04-01 15:57:36--  https://alt.qcri.org/semeval2017/task1/data/uploads/sts2017.eval.v1.1.zip\n",
            "Connecting to alt.qcri.org (alt.qcri.org)|37.186.61.205|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87902 (86K) [application/zip]\n",
            "Saving to: ‘sts2017.eval.v1.1.zip’\n",
            "\n",
            "sts2017.eval.v1.1.z 100%[===================>]  85.84K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-04-01 15:57:37 (684 KB/s) - ‘sts2017.eval.v1.1.zip’ saved [87902/87902]\n",
            "\n",
            "--2024-04-01 15:57:37--  http://alt.qcri.org/semeval2017/task1/data/uploads/sts2017.gs.zip\n",
            "Resolving alt.qcri.org (alt.qcri.org)... 37.186.61.205\n",
            "Connecting to alt.qcri.org (alt.qcri.org)|37.186.61.205|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://alt.qcri.org/semeval2017/task1/data/uploads/sts2017.gs.zip [following]\n",
            "--2024-04-01 15:57:37--  https://alt.qcri.org/semeval2017/task1/data/uploads/sts2017.gs.zip\n",
            "Connecting to alt.qcri.org (alt.qcri.org)|37.186.61.205|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3138 (3.1K) [application/zip]\n",
            "Saving to: ‘sts2017.gs.zip’\n",
            "\n",
            "sts2017.gs.zip      100%[===================>]   3.06K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-04-01 15:57:38 (1.34 GB/s) - ‘sts2017.gs.zip’ saved [3138/3138]\n",
            "\n",
            "Archive:  sts2017.eval.v1.1.zip\n",
            "  inflating: STS2017.eval.v1.1/LICENSE.txt  \n",
            "  inflating: STS2017.eval.v1.1/README.txt  \n",
            "  inflating: STS2017.eval.v1.1/STS.input.track1.ar-ar.txt  \n",
            "  inflating: STS2017.eval.v1.1/STS.input.track2.ar-en.txt  \n",
            "  inflating: STS2017.eval.v1.1/STS.input.track3.es-es.txt  \n",
            "  inflating: STS2017.eval.v1.1/STS.input.track4a.es-en.txt  \n",
            "  inflating: STS2017.eval.v1.1/STS.input.track4b.es-en.txt  \n",
            "  inflating: STS2017.eval.v1.1/STS.input.track5.en-en.txt  \n",
            "  inflating: STS2017.eval.v1.1/STS.input.track6.tr-en.txt  \n",
            "Archive:  sts2017.gs.zip\n",
            "   creating: STS2017.gs/\n",
            "  inflating: STS2017.gs/STS.gs.track1.ar-ar.txt  \n",
            "  inflating: STS2017.gs/STS.gs.track2.ar-en.txt  \n",
            "  inflating: STS2017.gs/STS.gs.track3.es-es.txt  \n",
            "  inflating: STS2017.gs/STS.gs.track4a.es-en.txt  \n",
            "  inflating: STS2017.gs/STS.gs.track4b.es-en.txt  \n",
            "  inflating: STS2017.gs/STS.gs.track5.en-en.txt  \n",
            "  inflating: STS2017.gs/STS.gs.track6.tr-en.txt  \n"
          ]
        }
      ],
      "source": [
        "# obtain the data\n",
        "!wget http://alt.qcri.org/semeval2017/task1/data/uploads/sts2017.eval.v1.1.zip\n",
        "!wget http://alt.qcri.org/semeval2017/task1/data/uploads/sts2017.gs.zip\n",
        "\n",
        "!unzip sts2017.eval.v1.1.zip\n",
        "!unzip sts2017.gs.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "d48a11ab",
      "metadata": {
        "id": "d48a11ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee7040c-07c5-435f-84e8-7339c0cbb8bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('A person is on a baseball team.',\n",
              " 'A person is playing basketball on a team.',\n",
              " 2.4)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "# load the data\n",
        "\n",
        "def load_STS_data():\n",
        "    with open(\"STS2017.gs/STS.gs.track5.en-en.txt\") as f:\n",
        "        labels = [float(line.strip()) for line in f]\n",
        "\n",
        "    text_a, text_b = [], []\n",
        "    with open(\"STS2017.eval.v1.1/STS.input.track5.en-en.txt\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip().split(\"\\t\")\n",
        "            text_a.append(line[0])\n",
        "            text_b.append(line[1])\n",
        "    return text_a, text_b, labels\n",
        "\n",
        "text_a, text_b, labels = load_STS_data()\n",
        "text_a[0], text_b[0], labels[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "dee8bcb4",
      "metadata": {
        "id": "dee8bcb4"
      },
      "outputs": [],
      "source": [
        "# some utils\n",
        "from scipy.stats import spearmanr\n",
        "def evaluate(predictions, labels):\n",
        "    print (\"spearman's rank correlation\", spearmanr(predictions, labels)[0])\n",
        "\n",
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cosine_similarity(a,b):\n",
        "    return dot(a, b)/(norm(a)*norm(b))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "46f02f97",
      "metadata": {
        "id": "46f02f97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbda77b9-7e3d-43c4-dbc6-fa4471398839"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spearman's rank correlation 0.6998056665685976\n"
          ]
        }
      ],
      "source": [
        "# Wordcounts baseline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vec = CountVectorizer()\n",
        "vec.fit(text_a + text_b)\n",
        "\n",
        "# encode documents\n",
        "text_a_encoded = np.array(vec.transform(text_a).todense())\n",
        "text_b_encoded = np.array(vec.transform(text_b).todense())\n",
        "\n",
        "# predict cosine similarities\n",
        "predictions = [cosine_similarity(a,b) for a,b in zip(text_a_encoded, text_b_encoded)]\n",
        "\n",
        "# evaluate\n",
        "evaluate(predictions, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "965242a5",
      "metadata": {
        "id": "965242a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb9a53d7-e797-4587-ec48-3ce0ee4f820d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spearman's rank correlation 0.2022986793129762\n"
          ]
        }
      ],
      "source": [
        "from gensim.models.doc2vec import TaggedDocument\n",
        "from gensim.models import Doc2Vec\n",
        "\n",
        "def infer_vectors(model, tagged_texts):\n",
        "    return [model.infer_vector(doc.words) for doc in tagged_texts]\n",
        "\n",
        "def create_tagged_documents(texts):\n",
        "    tagged_texts = [TaggedDocument(words=text.split(), tags=[i]) for i, text in enumerate(texts)]\n",
        "    return tagged_texts\n",
        "\n",
        "tagged_text_a = create_tagged_documents(text_a)\n",
        "tagged_text_b = create_tagged_documents(text_b)\n",
        "\n",
        "##TODO train Doc2Vec on the texts in the dataset\n",
        "model = Doc2Vec(vector_size=300, min_count=2, epochs=20)\n",
        "model.build_vocab(tagged_text_a + tagged_text_b)\n",
        "model.train(tagged_text_a + tagged_text_b, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "\n",
        "##TODO derive the word vectors for each text in the dataset\n",
        "text_a_vectors = infer_vectors(model, tagged_text_a)\n",
        "text_b_vectors = infer_vectors(model, tagged_text_b)\n",
        "\n",
        "##TODO compute cosine similarity between the text pairs and evaluate spearman's rank correlation\n",
        "predictions = [cosine_similarity(a, b) for a, b in zip(text_a_vectors, text_b_vectors)]\n",
        "evaluate(predictions, labels)\n",
        "## Don't worry if results are not satisfactory using Doc2Vec (the dataset is too small to train good embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "e67b67c8",
      "metadata": {
        "id": "e67b67c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad3b3470-bdf5-44ba-9b48-3df1e5ee6416"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spearman's rank correlation 0.48796451382976114\n"
          ]
        }
      ],
      "source": [
        "##TODO do the same with embeddings provided by spaCy\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def get_spacy_vectors(texts):\n",
        "    return [nlp(text).vector for text in texts]\n",
        "\n",
        "text_a_vectors_spacy = get_spacy_vectors(text_a)\n",
        "text_b_vectors_spacy = get_spacy_vectors(text_b)\n",
        "\n",
        "predictions_spacy = [cosine_similarity(a, b) for a, b in zip(text_a_vectors_spacy, text_b_vectors_spacy)]\n",
        "evaluate(predictions_spacy, labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8aoD3HJvFA5",
        "outputId": "b8d46e9d-6366-4d5d-dc45-794a61b0bb86"
      },
      "id": "W8aoD3HJvFA5",
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-2.6.1-py3-none-any.whl (163 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/163.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m153.6/163.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m533.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 sentence-transformers-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##TODO do the same with SBERT embeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "model = \"bert-base-nli-mean-tokens\"\n",
        "sbert_model = SentenceTransformer(model)\n",
        "\n",
        "text_a_vectors_sbert = sbert_model.encode(text_a)\n",
        "text_b_vectors_sbert = sbert_model.encode(text_b)\n",
        "\n",
        "predictions_sbert = [cosine_similarity(a, b) for a, b in zip(text_a_vectors_sbert, text_b_vectors_sbert)]\n",
        "evaluate(predictions_sbert, labels)"
      ],
      "metadata": {
        "id": "_wiUJYr30pHY"
      },
      "id": "_wiUJYr30pHY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PduK1Zop0vGR"
      },
      "id": "PduK1Zop0vGR",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}